{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from scipy.stats import spearmanr\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(alg,X_test,y_test):\n",
    "    y_test_pred = alg.predict(X_test)\n",
    "    print('Test MAE: {:0.4f}'.format(metrics.mean_absolute_error(y_test, y_test_pred)))\n",
    "    print('Test MSE: {:0.4f}'.format(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "    print('Test RMSE: {:0.4f}'.format(metrics.mean_squared_error(y_test, y_test_pred, squared=False)))\n",
    "    print('Test R2: {:0.4f}'.format(metrics.r2_score(y_test, y_test_pred)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, X_train, y_train, useTrainCV=True, cv_folds=5, early_stopping_rounds=10):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='rmse', early_stopping_rounds=early_stopping_rounds, verbose_eval=False)\n",
    "        print(cvresult['test-rmse-mean'].min())\n",
    "        print(cvresult['test-rmse-mean'].argmin())\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train,eval_metric='rmse')\n",
    "        \n",
    "    #Predict training set:\n",
    "    evaluate(alg,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"udemy/course_all_features.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = df.iloc[:, 19:3859]\n",
    "text_features = StandardScaler().fit_transform(text_features)\n",
    "pca = PCA(n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_features = pca.fit_transform(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_df = pd.DataFrame(new_text_features)\n",
    "new_text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_features = df2.iloc[:, 0:18]\n",
    "new_df = pd.concat([rest_features, new_text_df],axis=1)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = np.log2(new_df['num_monthly_reviews'])\n",
    "enrollments = np.log2(new_df['num_monthly_enrollments'])\n",
    "\n",
    "features = new_df.drop(['courseID','num_monthly_reviews','num_monthly_enrollemnts'],1)\n",
    "features = pd.get_dummies(data=features, columns=[\"category\",\"instructionsl_level\",\"published_year\",\"published_month\"])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, reviews, test_size=0.2, random_state=121212)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred =  lr.predict(X_train)\n",
    "print('Training MAE: {:0.4f}'.format(metrics.mean_absolute_error(y_train, y_pred)))\n",
    "print('Training MSE: {:0.4f}'.format(metrics.mean_squared_error(y_train, y_pred, squared=False)))\n",
    "evaluate(lr,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 600, num = 3)]\n",
    "# Number of features to consider at every split\n",
    "n_test_features = features.shape[1]/2 \n",
    "max_features = ['auto', 'sqrt', n_test_features]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 50, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# Random search of parameters, using 5 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "rf_random.best_params_, rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_random.predict(X_train)\n",
    "y_test_pred = best_random.predict(X_test)\n",
    "print('Test MAE: {:0.4f}'.format(metrics.mean_absolute_error(y_test, y_test_pred)))\n",
    "print('Test MSE: {:0.4f}'.format(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print('Test RMSE: {:0.4f}'.format(metrics.mean_squared_error(y_test, y_test_pred, squared=False)))\n",
    "print('Test R2: {:0.4f}'.format(metrics.r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [15, 20],\n",
    "    'max_features': [600, 700, 800],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'n_estimators': [400, 500, 600]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train,y_train)\n",
    "grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews\n",
    "rf = RandomForestRegressor(max_depth=20,max_features=700,min_samples_leaf=1, min_samples_split=2,n_estimators=500,bootstrap=True,n_jobs=-1)\n",
    "rf.fit(X_train,y_train)\n",
    "evaluate(rf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBRegressor(learning_rate =0.1, n_estimators=444, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,nthread=4, scale_pos_weight=1, seed=42), \n",
    " param_grid = param_test1,scoring='neg_root_mean_squared_error',n_jobs=4,cv=10)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[4,5,6],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBRegressor(learning_rate =0.1, n_estimators=444, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,nthread=4, scale_pos_weight=1, seed=42), \n",
    " param_grid = param_test2,scoring='neg_root_mean_squared_error',n_jobs=4,cv=10)\n",
    "#gsearch1.fit(X_train,y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2b = {\n",
    " 'min_child_weight':[6,8,10]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = xgb.XGBRegressor(learning_rate =0.1, n_estimators=444, max_depth=6,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,nthread=4, scale_pos_weight=1, seed=42), \n",
    " param_grid = param_test2b,scoring='neg_root_mean_squared_error',n_jobs=4,cv=10)\n",
    "gsearch2b.fit(X_train,y_train)\n",
    "gsearch2b.best_params_, gsearch2b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = xgb.XGBRegressor(learning_rate =0.1, n_estimators=444, max_depth=6,\n",
    " min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,nthread=4, scale_pos_weight=1, seed=42), \n",
    " param_grid = param_test3,scoring='neg_root_mean_squared_error',n_jobs=4,cv=10)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(4,11)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(4,11)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = xgb.XGBRegressor(learning_rate =0.1, n_estimators=260, max_depth=6,\n",
    " min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,nthread=4, scale_pos_weight=1, seed=42), \n",
    " param_grid = param_test4,scoring='neg_root_mean_squared_error',n_jobs=4,cv=10)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    " 'reg_lambda':[1e-5, 1e-2, 0.1, 1, 100]   \n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = xgb.XGBRegressor(learning_rate =0.1, n_estimators=260, max_depth=6,\n",
    " min_child_weight=6, gamma=0, subsample=0.85, colsample_bytree=0.7,nthread=4, scale_pos_weight=1, seed=42), \n",
    " param_grid = param_test6,scoring='neg_root_mean_squared_error',n_jobs=4,cv=10)\n",
    "gsearch6.fit(X_train,y_train)\n",
    "gsearch6.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = xgb.XGBRegressor(\n",
    "                 gamma=0,                 \n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=6,\n",
    "                 min_child_weight=1,\n",
    "                 n_estimators=5000,                                                                    \n",
    "                 colsample_bytree=0.6,\n",
    "                 subsample=1,\n",
    "                 seed=42) \n",
    "modelfit(xgb_best, X_train, y_train)\n",
    "evaluate(xgb_best,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_trainscaled=sc_X.fit_transform(X_train)\n",
    "X_testscaled=sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(64,32,16),activation=\"relu\" ,random_state=42, max_iter=2000,early_stopping=True,n_iter_no_change=10)\n",
    "mlp.fit(X_trainscaled, y_train)\n",
    "evaluate(mlp,X_testscaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(64,32,16), (512,256,128), (2048,1024,512), (512,256,128,64)],\n",
    "    'activation': ['relu','tanh','identity'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'learning_rate':['constant','adaptive']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(512,256,128,64),activation=\"relu\" ,alpha=0.0001, solver='adam',random_state=42, max_iter=2000,early_stopping=True,n_iter_no_change=10)\n",
    "grid = GridSearchCV(mlp, param_grid, n_jobs= -1, cv=5)\n",
    "grid.fit(X_trainscaled, y_train)\n",
    "print(grid.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = grid.best_estimator_\n",
    "evaluate(best_mlp,X_testscaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(2048,1024,512),activation=\"relu\" ,random_state=42, max_iter=2000,early_stopping=True,learning_rate='constant',n_iter_no_change=10)\n",
    "mlp1f.fit(X_trainscaled, y_train)\n",
    "evaluate(mlp1f,X_testscaled,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
